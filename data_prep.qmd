---
title: "Data Preparation"
author: "Kenneth Yong"
---

## Overview

This document describes the data preparation process for combining and enriching historical weather data for Singapore from 2020 to 2024.

## 1. Download Historical Weather Data

Downloaded the daily weather data for each year from the [Meteorological Service Singapore](https://www.weather.gov.sg/climate-historical-daily/) website. Only [active full aws stations](https://www.weather.gov.sg/wp-content/uploads/2024/08/Station_Records.pdf) were considered. While we were downloading the datasets, Marina Barrage, Semakau Island and Tengah stations were observed to contain a significant amount of missing data (2 years worth of missing data). Therefore, these stations were omitted. The downloaded CSV files were placed into a single folder.

## 2. Combine All CSV Files into One Dataset

We used the `data.table` package to read and combine multiple CSV files stored in one directory.

``` r
library(data.table)

file_list <- list.files(pattern = "\\.csv$")

# Read and combine all CSVs
weather_data <- rbindlist(lapply(file_list, fread), fill = TRUE)
```

## 3. Convert Year, Month, Day to a Single Date Column

Since each CSV file includes columns for `Year`, `Month`, and `Day`:

``` r
# Combine year, month, and day into a proper date
weather_data[, Date := as.Date(paste(Year, Month, Day, sep = "-"))]

# Remove the original columns
weather_data[, c("Year", "Month", "Day") := NULL]
```

## 4. Add Region Column

We map the region using a predefined vector based on the station name.

``` r
region_map <- c(
  "Admiralty" = "North", 
  "Ang Mo Kio" = "Northeast",
  "Changi" = "East",
  "Choa Chu Kang (South)" = "West",
  "Clementi" = "West",
  "East Coast Parkway" = "East",
  "Jurong (West)" = "West",
  "Jurong Island" = "West",
  "Newton" = "Central",
  "Pasir Panjang" = "Central",
  "Paya Lebar" = "Central",
  "Pulau Ubin" = "Northeast",
  "Seletar" = "North",
  "Sembawang" = "North",
  "Sentosa Island" = "Central",
  "Tai Seng" = "Northeast",
  "Tuas South" = "West"
)

weather_data[, Region := region_map[Station]]
```

## 5. Add Latitude and Longitude

We join latitude and longitude coordinates using a [reference table](https://www.weather.gov.sg/wp-content/uploads/2024/08/Station_Records.pdf).

``` r
data_coords <- data.table(
  Station = c("Admiralty", "Ang Mo Kio", "Changi", "Choa Chu Kang (South)", "Clementi", "East Coast Parkway", 
              "Jurong (West)", "Jurong Island", "Marina Barrage", "Newton", "Pasir Panjang", "Paya Lebar", 
              "Pulau Ubin", "Seletar", "Sembawang", "Sentosa Island", "Tai Seng", "Tengah", "Tuas South"),
  Latitude = c(1.4439, 1.3793, 1.3678, 1.3729, 1.3318, 1.3133, 1.3458, 1.2542, 1.2799, 1.2824, 
               1.3571, 1.4168, 1.4167, 1.4250, 1.2503, 1.3406, 1.2938),
  Longitude = c(103.7854, 103.8500, 103.9823, 103.7224, 103.7762, 103.9620, 103.6817, 103.6741, 103.8703, 
                 103.7545, 103.9037, 103.9673, 103.8650, 103.8200, 103.8275, 103.8882, 
                103.6184)
)

weather_data <- merge(weather_data, data_coords, by = "Station", all.x = TRUE)
```

## 6. Sort Data

Group by station alphabetically and sort dates chronologically within each station.

``` r
# Sort data
setorder(weather_data, Station, Date)
```

## 7. Convert column data type

Convert data types such that 'Region' and 'Station' remain as character, 'Date' becomes a proper date type and all other columns become numeric.

``` r
weather_data_updated <- weather_data %>%
  mutate(
    Date = dmy(Date),  # Convert Date column to Date format (from d/m/yyyy)
    across(
      .cols = -c(Region, Station, Date),  # Select all except these columns
      .fns = ~ as.numeric(.)
    )
  )
```

## 8. Export datasets as CSV and RDS

``` r
# Export as CSV
write.csv(weather_data_updated, "weather_data_updated.csv", row.names = FALSE)

# Export as RDS
saveRDS(weather_data_updated, "weather_data_updated.rds")
```

## 9. Check for Duplicates and Missing Values

Ensure data integrity by checking for duplicates and missing values.

```{r}
pacman::p_load(tidyverse, naniar, lubridate, imputeTS)

weather_data_updated <-read_csv("data/weather_data_updated.csv")

duplicates <- weather_data_updated %>% 
  filter(duplicated(.))

print(duplicates)
vis_miss(weather_data_updated)
```

## 10. Remove unused columns

We remove the columns that we will not used: Highest 30 min Rainfall (mm), Highest 60 min Rainfall (mm), Highest 120 min Rainfall (mm), Mean Wind Speed (km/h) and Max Wind Speed (km/h).

```{r}
weather_data_updated <- weather_data_updated[, !(names(weather_data_updated) %in% c(
  "Highest 30 min Rainfall (mm)",
  "Highest 60 min Rainfall (mm)",
  "Highest 120 min Rainfall (mm)",
  "Mean Wind Speed (km/h)",
  "Max Wind Speed (km/h)"
))]
```

## 11. Impute missing values

This code fills in missing weather data using a 7-day moving average, doing so separately for each weather station.

```{r}
weather_variables <- c("Daily Rainfall Total (mm)", "Mean Temperature (°C)", "Maximum Temperature (°C)", "Minimum Temperature (°C)")

weather_data_cleaned <- weather_data_updated

for(variable in weather_variables) {
  weather_data_cleaned[[variable]] <- as.numeric(as.character(weather_data_cleaned[[variable]]))
  
  weather_data_cleaned <- weather_data_cleaned %>%
    group_by(Station) %>%
    arrange(Station, Date) %>%
    mutate("{variable}" := round(na_ma(.data[[variable]], k = 7, weighting = "simple"), 1)) %>%
    ungroup()
}
```

```{r}
glimpse(weather_data_cleaned)
vis_miss(weather_data_cleaned)
```

## 12. Export prepared datasets as CSV and RDS

```{r}
# Export as CSV
write.csv(weather_data_cleaned, "weather_data_cleaned.csv", row.names = FALSE)

# Export as RDS
saveRDS(weather_data_cleaned, "weather_data_cleaned.rds")
```